{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import folium\n",
    "from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataFile/Gwangju_Bus_Route_Stop_Time_Based_Passenger_Counts_2024_04.xlsx'\n",
    "\n",
    "def read_excel_in_chunks(file_path, sheet_name, chunk_size=10000):\n",
    "    wb = load_workbook(filename=file_path, read_only=True)\n",
    "    ws = wb[sheet_name]\n",
    "\n",
    "    rows = ws.iter_rows(values_only=True)\n",
    "    headers = next(rows)  # 첫 번째 행을 헤더로 사용\n",
    "    chunks = []\n",
    "\n",
    "    while True:\n",
    "        chunk = []\n",
    "        try:\n",
    "            for _ in range(chunk_size):\n",
    "                chunk.append(next(rows))\n",
    "        except StopIteration:\n",
    "            if chunk:\n",
    "                chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "            break\n",
    "        \n",
    "        chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# 첫 번째 시트를 청크 단위로 읽어오기\n",
    "sheet_name = '24.4.1.~4.7.'\n",
    "df = read_excel_in_chunks(file_path, sheet_name, chunk_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임의 크기(사이즈)를 확인\n",
    "data_size = df.shape\n",
    "\n",
    "# 행과 열의 수를 출력\n",
    "print(f\"Number of rows: {data_size[0]}\")\n",
    "print(f\"Number of columns: {data_size[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 광주광역시 버스 정류장 2024.04 승하차 엑셀 파일 데이터 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataFile/Gwangju_Bus_Route_Stop_Time_Based_Passenger_Counts_2024_04.xlsx'\n",
    "\n",
    "def read_excel_in_chunks(file_path, sheet_name, chunk_size=10000):\n",
    "    wb = load_workbook(filename=file_path, read_only=True)\n",
    "    ws = wb[sheet_name]\n",
    "\n",
    "    rows = ws.iter_rows(values_only=True)\n",
    "    headers = next(rows)  # 첫 번째 행을 헤더로 사용\n",
    "    chunks = []\n",
    "\n",
    "    while True:\n",
    "        chunk = []\n",
    "        try:\n",
    "            for _ in range(chunk_size):\n",
    "                chunk.append(next(rows))\n",
    "        except StopIteration:\n",
    "            if chunk:\n",
    "                chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "            break\n",
    "        \n",
    "        if chunk:\n",
    "            chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# 시트 이름 리스트\n",
    "sheet_names = ['24.4.1.~4.7.', '24.4.8.~4.14.', '24.4.15.~4.21.', '24.4.22.~4.28.', '24.4.29.~30.']\n",
    "\n",
    "# 각 시트를 읽어서 DataFrame에 저장\n",
    "dfs = []\n",
    "for i, sheet_name in enumerate(sheet_names, start=1):\n",
    "    df = read_excel_in_chunks(file_path, sheet_name, chunk_size=10000)\n",
    "    dfs.append(df)\n",
    "    # DataFrame 저장\n",
    "    globals()[f'df{i}'] = df\n",
    "\n",
    "# 각 DataFrame 병합 및 거래건수 합산\n",
    "def merge_and_aggregate(dfs):\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    # 그룹화 및 거래건수 합산\n",
    "    merged_df = combined_df.groupby(['노선명', '정류장명', 'ARS_ID', '시간', '승하차']).agg({'거래건수': 'sum'}).reset_index()\n",
    "    return merged_df\n",
    "\n",
    "merged_df = merge_and_aggregate(dfs)\n",
    "\n",
    "# 결과 확인\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임의 크기(사이즈)를 확인\n",
    "data_size = merged_df.shape\n",
    "\n",
    "# 행과 열의 수를 출력\n",
    "print(f\"Number of rows: {data_size[0]}\")\n",
    "print(f\"Number of columns: {data_size[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합된 데이터를 엑셀 파일로 저장\n",
    "output_file_path = 'dataFile/Merged_Gwangju_Bus_Data_2024_04.xlsx'\n",
    "merged_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully exported to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 광주광역시 버스 정류장 2024.01 ~ 03 승하차 엑셀 파일 데이터 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataFile/Gwangju_Bus_Route_Stop_Time_Based_Passenger_Counts_2024_01.xlsx'\n",
    "\n",
    "def read_excel_in_chunks(file_path, sheet_name, chunk_size=10000):\n",
    "    wb = load_workbook(filename=file_path, read_only=True)\n",
    "    ws = wb[sheet_name]\n",
    "\n",
    "    rows = ws.iter_rows(values_only=True)\n",
    "    headers = next(rows)  # 첫 번째 행을 헤더로 사용\n",
    "    chunks = []\n",
    "\n",
    "    while True:\n",
    "        chunk = []\n",
    "        try:\n",
    "            for _ in range(chunk_size):\n",
    "                chunk.append(next(rows))\n",
    "        except StopIteration:\n",
    "            if chunk:\n",
    "                chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "            break\n",
    "        \n",
    "        if chunk:\n",
    "            chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# 시트 이름 리스트\n",
    "sheet_names = ['24.1.1.~1.7.', '24.1.8.~1.14.', '24.1.15.~1.21.', '24.1.22.~1.28.', '24.1.29.~1.31.']\n",
    "\n",
    "# 각 시트를 읽어서 DataFrame에 저장\n",
    "dfs = []\n",
    "for i, sheet_name in enumerate(sheet_names, start=1):\n",
    "    df = read_excel_in_chunks(file_path, sheet_name, chunk_size=10000)\n",
    "    dfs.append(df)\n",
    "    # DataFrame 저장\n",
    "    globals()[f'df{i}'] = df\n",
    "\n",
    "# 각 DataFrame 병합 및 거래건수 합산\n",
    "def merge_and_aggregate(dfs):\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    # 그룹화 및 거래건수 합산\n",
    "    merged_df = combined_df.groupby(['노선명', '정류장명', 'ARS_ID', '시간', '승하차']).agg({'거래건수': 'sum'}).reset_index()\n",
    "    return merged_df\n",
    "\n",
    "merged_df = merge_and_aggregate(dfs)\n",
    "\n",
    "# 병합된 데이터를 엑셀 파일로 저장\n",
    "output_file_path = 'dataFile/Merged_Gwangju_Bus_Data_2024_01.xlsx'\n",
    "merged_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully exported to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 광주광역시 버스 정류장 2024.01 ~ 04 승하차 엑셀 파일 합병 데이터 파일 최종 합병"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로 리스트\n",
    "file_paths = [\n",
    "    'dataFile/Merged_Gwangju_Bus_Data_2024_01.xlsx',\n",
    "    'dataFile/Merged_Gwangju_Bus_Data_2024_02.xlsx',\n",
    "    'dataFile/Merged_Gwangju_Bus_Data_2024_03.xlsx',\n",
    "    'dataFile/Merged_Gwangju_Bus_Data_2024_04.xlsx'\n",
    "]\n",
    "\n",
    "# 각 파일의 데이터를 읽어서 하나의 DataFrame에 병합\n",
    "combined_dfs = []\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_excel(file_path)\n",
    "    combined_dfs.append(df)\n",
    "\n",
    "# 모든 파일을 하나의 DataFrame으로 병합\n",
    "combined_df = pd.concat(combined_dfs, ignore_index=True)\n",
    "\n",
    "# 거래건수 합산\n",
    "merged_df = combined_df.groupby(['노선명', '정류장명', 'ARS_ID', '시간', '승하차']).agg({'거래건수': 'sum'}).reset_index()\n",
    "\n",
    "# 병합된 데이터를 엑셀 파일로 저장\n",
    "output_file_path = 'dataFile/Merged_Gwangju_Bus_Data_2024_All.xlsx'\n",
    "merged_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully exported to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전국 버스 정류장 위치 데이터에서 광주광역시 위치 데이터 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'dataFile/MOLIT_National_Bus_Stop_Location_Information_20231016.csv'\n",
    "excel_file_path = 'dataFile/Merged_Gwangju_Bus_Data_2024_All.xlsx'\n",
    "\n",
    "# 인코딩 감지\n",
    "with open(csv_file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "encoding = result['encoding']\n",
    "print(f\"Detected encoding: {encoding}\")\n",
    "\n",
    "# CSV 파일을 청크 단위로 읽고 필터링\n",
    "filtered_csv_data = []\n",
    "chunk_size = 10000\n",
    "\n",
    "for chunk in pd.read_csv(csv_file_path, encoding=encoding, chunksize=chunk_size):\n",
    "    filtered_chunk = chunk[(chunk['도시명'] == '광주광역시') & (chunk['관리도시명'] == '광주')]\n",
    "    filtered_csv_data.append(filtered_chunk)\n",
    "\n",
    "df_csv_filtered = pd.concat(filtered_csv_data, ignore_index=True)\n",
    "df_csv_filtered = df_csv_filtered[['모바일단축번호', '위도', '경도']]\n",
    "print(f\"Filtered CSV size: {df_csv_filtered.shape}\")\n",
    "\n",
    "# 엑셀 파일을 청크 단위로 읽고 병합하는 함수\n",
    "def read_excel_in_chunks(file_path, chunk_size=10000):\n",
    "    wb = load_workbook(filename=file_path, read_only=True)\n",
    "    ws = wb.active\n",
    "\n",
    "    rows = ws.iter_rows(values_only=True)\n",
    "    headers = next(rows)  # 첫 번째 행을 헤더로 사용\n",
    "    merged_data = []\n",
    "\n",
    "    chunk = []\n",
    "    for i, row in enumerate(rows, 1):\n",
    "        chunk.append(row)\n",
    "        if i % chunk_size == 0:\n",
    "            df_chunk = pd.DataFrame(chunk, columns=headers)\n",
    "            df_chunk = df_chunk.merge(df_csv_filtered, left_on='ARS_ID', right_on='모바일단축번호', how='left')\n",
    "            merged_data.append(df_chunk)\n",
    "            chunk = []\n",
    "\n",
    "    # 남아있는 마지막 청크 처리\n",
    "    if chunk:\n",
    "        df_chunk = pd.DataFrame(chunk, columns=headers)\n",
    "        df_chunk = df_chunk.merge(df_csv_filtered, left_on='ARS_ID', right_on='모바일단축번호', how='left')\n",
    "        merged_data.append(df_chunk)\n",
    "\n",
    "    return pd.concat(merged_data, ignore_index=True)\n",
    "\n",
    "# 엑셀 파일 데이터를 청크 단위로 읽고 병합\n",
    "df_merged = read_excel_in_chunks(excel_file_path, chunk_size=10000)\n",
    "\n",
    "# 병합된 데이터를 엑셀 파일로 저장\n",
    "output_file_path = 'dataFile/Merged_Gwangju_Bus_Data_With_Coordinates.xlsx'\n",
    "df_merged.to_excel(output_file_path, index=False)\n",
    "print(f\"Data has been successfully exported to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_in_chunks(file_path, chunk_size=10000):\n",
    "    wb = load_workbook(filename=file_path, read_only=True)\n",
    "    ws = wb.active  # 첫 번째 시트를 선택\n",
    "\n",
    "    rows = ws.iter_rows(values_only=True)\n",
    "    headers = next(rows)  # 첫 번째 행을 헤더로 사용\n",
    "    chunks = []\n",
    "\n",
    "    while True:\n",
    "        chunk = []\n",
    "        try:\n",
    "            for _ in range(chunk_size):\n",
    "                chunk.append(next(rows))\n",
    "        except StopIteration:\n",
    "            if chunk:\n",
    "                chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "            break\n",
    "        \n",
    "        if chunk:  # Ensure we only append non-empty chunks\n",
    "            chunks.append(pd.DataFrame(chunk, columns=headers))\n",
    "\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# 파일 경로\n",
    "file_path = 'dataFile/Merged_Gwangju_Bus_Data_With_Coordinates.xlsx'\n",
    "\n",
    "# 엑셀 파일을 청크 단위로 읽어오기\n",
    "bus_data_with_coordinates = read_excel_in_chunks(file_path, chunk_size=10000)\n",
    "\n",
    "bus_data_with_coordinates.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getOn, getOff, transfer 데이터를 필터링하여 각각의 DataFrame으로 분리\n",
    "getOn_filtered = bus_data_with_coordinates[bus_data_with_coordinates['승하차'] == '승차']\n",
    "getOff_filtered = bus_data_with_coordinates[bus_data_with_coordinates['승하차'] == '하차']\n",
    "transfer_filtered = bus_data_with_coordinates[bus_data_with_coordinates['승하차'] == '환승']\n",
    "\n",
    "# 피벗 테이블 생성 함수\n",
    "def create_pivot_table(df, label):\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=['일자', '노선명', '정류장명', 'ARS_ID', '위도', '경도'],\n",
    "        columns='시간',\n",
    "        values='거래건수',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    pivot_df.columns = [f\"{col}시 {label}\" for col in pivot_df.columns]\n",
    "    pivot_df.reset_index(inplace=True)\n",
    "    pivot_df.columns.name = None\n",
    "    return pivot_df\n",
    "\n",
    "# 각 데이터 프레임에 대해 피벗 테이블 생성\n",
    "getOn_pivot = create_pivot_table(getOn_filtered, '승차인원')\n",
    "getOff_pivot = create_pivot_table(getOff_filtered, '하차인원')\n",
    "transfer_pivot = create_pivot_table(transfer_filtered, '환승인원')\n",
    "\n",
    "# 파일 저장 경로\n",
    "output_file_path_getOn = 'dataFile/Gwangju_Bus_Data_getOn_Pivot.xlsx'\n",
    "output_file_path_getOff = 'dataFile/Gwangju_Bus_Data_getOff_Pivot.xlsx'\n",
    "output_file_path_transfer = 'dataFile/Gwangju_Bus_Data_transfer_Pivot.xlsx'\n",
    "\n",
    "# 피벗 테이블을 엑셀 파일로 저장\n",
    "getOn_pivot.to_excel(output_file_path_getOn, index=False)\n",
    "getOff_pivot.to_excel(output_file_path_getOff, index=False)\n",
    "transfer_pivot.to_excel(output_file_path_transfer, index=False)\n",
    "\n",
    "print(f\"Data has been successfully exported to {output_file_path_getOn}\")\n",
    "print(f\"Data has been successfully exported to {output_file_path_getOff}\")\n",
    "print(f\"Data has been successfully exported to {output_file_path_transfer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "getOn_file_path = 'dataFile/Gwangju_Bus_Data_getOn_Pivot.xlsx'\n",
    "getOff_file_path = 'dataFile/Gwangju_Bus_Data_getOff_Pivot.xlsx'\n",
    "transfer_file_path = 'dataFile/Gwangju_Bus_Data_transfer_Pivot.xlsx'\n",
    "\n",
    "getOn_df = pd.read_excel(getOn_file_path)\n",
    "getOff_df = pd.read_excel(getOff_file_path)\n",
    "transfer_df = pd.read_excel(transfer_file_path)\n",
    "\n",
    "# 5시부터 23시까지의 합계 컬럼 생성\n",
    "getOn_df['총 승차인원'] = getOn_df.loc[:, '5시 승차인원':'23시 승차인원'].sum(axis=1)\n",
    "getOff_df['총 하차인원'] = getOff_df.loc[:, '5시 하차인원':'23시 하차인원'].sum(axis=1)\n",
    "transfer_df['총 환승인원'] = transfer_df.loc[:, '5시 환승인원':'23시 환승인원'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정류장 승차, 하차, 환승 혼잡도 표 분석 (시간대별 총 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors  # 이 줄을 추가하여 mcolors 모듈을 임포트합니다\n",
    "# 승차 데이터를 분석하기 위한 데이터 프레임 생성\n",
    "getOn_analyze_tb = getOn_df.drop(['일자', '노선명', '승하차', '위도', '경도'], axis=1)\n",
    "\n",
    "# 총 승차인원을 기준으로 내림차순 정렬\n",
    "getOn_analyze_tb = getOn_analyze_tb.sort_values(by='총 승차인원', ascending=False)\n",
    "\n",
    "# 총 승차인원 컬럼 제거 \n",
    "getOn_analyze_tb = getOn_analyze_tb.drop('총 승차인원', axis=1)\n",
    "\n",
    "# 사용자 지정 색상 맵 생성 (흰색에서 파란색으로)\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", [\"white\", \"blue\"])\n",
    "\n",
    "# 배경 그라데이션을 적용할 칼럼 목록\n",
    "columns_to_style = [col for col in getOn_analyze_tb.columns if col not in ['정류장명', 'ARS_ID']]\n",
    "\n",
    "# 텍스트 가운데 정렬을 적용할 칼럼 목록\n",
    "columns_to_align_center = columns_to_style\n",
    "\n",
    "# 배경 그라데이션 및 텍스트 가운데 정렬 적용\n",
    "def style_specific_columns(styler):\n",
    "    styler = styler.background_gradient(cmap=cmap, subset=columns_to_style)\n",
    "    styler = styler.set_properties(**{'text-align': 'center'}, subset=columns_to_align_center)\n",
    "    return styler\n",
    "\n",
    "getOn_analyze_tb_styled = getOn_analyze_tb.style.pipe(style_specific_columns).hide(axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스타일이 적용된 데이터프레임을 HTML 파일로 저장 (UTF-8 인코딩 지정)\n",
    "html = getOn_analyze_tb_styled.to_html()\n",
    "\n",
    "# 메타 태그를 추가한 HTML 내용\n",
    "html_with_meta = '<meta charset=\"UTF-8\">' + html\n",
    "\n",
    "with open(\"정류장 승차 인원 혼잡도 표.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_with_meta)\n",
    "\n",
    "print(\"HTML 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_styled_table(df, total_col, output_file, color_map, drop_cols):\n",
    "    # 데이터를 분석하기 위한 데이터 프레임 생성\n",
    "    analyze_tb = df.drop(drop_cols, axis=1)\n",
    "\n",
    "    # 총 인원을 기준으로 내림차순 정렬\n",
    "    analyze_tb = analyze_tb.sort_values(by=total_col, ascending=False)\n",
    "\n",
    "    # 총 인원 컬럼 제거 \n",
    "    analyze_tb = analyze_tb.drop(total_col, axis=1)\n",
    "\n",
    "    # 배경 그라데이션을 적용할 칼럼 목록\n",
    "    columns_to_style = [col for col in analyze_tb.columns if col not in ['정류장명', 'ARS_ID']]\n",
    "\n",
    "    # 텍스트 가운데 정렬을 적용할 칼럼 목록\n",
    "    columns_to_align_center = columns_to_style\n",
    "\n",
    "    # 배경 그라데이션 및 텍스트 가운데 정렬 적용\n",
    "    def style_specific_columns(styler):\n",
    "        styler = styler.background_gradient(cmap=color_map, subset=columns_to_style)\n",
    "        styler = styler.set_properties(**{'text-align': 'center'}, subset=columns_to_align_center)\n",
    "        return styler\n",
    "\n",
    "    styled_df = analyze_tb.style.pipe(style_specific_columns).hide(axis='index')\n",
    "\n",
    "    # 스타일이 적용된 데이터프레임을 HTML 파일로 저장 (UTF-8 인코딩 지정)\n",
    "    html = styled_df.to_html()\n",
    "\n",
    "    # 메타 태그를 추가한 HTML 내용\n",
    "    html_with_meta = '<meta charset=\"UTF-8\">' + html\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html_with_meta)\n",
    "\n",
    "    print(f\"{output_file} 파일로 저장되었습니다.\")\n",
    "\n",
    "# 사용자 지정 색상 맵 생성 (흰색에서 파란색으로)\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", [\"white\", \"blue\"])\n",
    "\n",
    "# 파일 저장\n",
    "create_styled_table(getOn_df, '총 승차인원', \"정류장_승차_인원_혼잡도_표.html\", cmap, ['일자', '노선명', '승하차', '위도', '경도'])\n",
    "create_styled_table(getOff_df, '총 하차인원', \"정류장_하차_인원_혼잡도_표.html\", cmap, ['일자', '노선명', '승하차', '위도', '경도'])\n",
    "create_styled_table(transfer_df, '총 환승인원', \"정류장_환승_인원_혼잡도_표.html\", cmap, ['일자', '노선명', '승하차', '위도', '경도'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 승차 출근, 퇴근 시간 혼잡도(표, 막대 그래프)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간과 퇴근 시간 동안의 승차 인원을 계산\n",
    "getOn_df['출근 시간 총 승차인원'] = getOn_df[['6시 승차인원', '7시 승차인원', '8시 승차인원', '9시 승차인원']].sum(axis=1)\n",
    "getOn_df['퇴근 시간 총 승차인원'] = getOn_df[['17시 승차인원', '18시 승차인원', '19시 승차인원', '20시 승차인원', '21시 승차인원', '22시 승차인원']].sum(axis=1)\n",
    "\n",
    "# 출근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_morning = getOn_df.nlargest(10, '출근 시간 총 승차인원')\n",
    "\n",
    "# 퇴근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_evening = getOn_df.nlargest(10, '퇴근 시간 총 승차인원')\n",
    "\n",
    "# 색상 설정을 위한 함수\n",
    "def get_colors(values):\n",
    "    norm = mcolors.Normalize(vmin=values.min(), vmax=values.max())\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", [\"gray\", \"blue\"])\n",
    "    return [cmap(norm(val)) for val in values]\n",
    "\n",
    "# 정류장명과 노선명을 합치는 함수\n",
    "def combine_station_route(df):\n",
    "    df['정류장명'] = df['정류장명'] + ' (' + df['노선명'] + ')'\n",
    "    return df\n",
    "\n",
    "# 정류장명과 노선명을 합침\n",
    "top_10_morning = combine_station_route(top_10_morning)\n",
    "top_10_evening = combine_station_route(top_10_evening)\n",
    "\n",
    "# Top 10 정류장의 시간대별 승차 인원수 시각화\n",
    "def plot_top_10(df, title):\n",
    "    df.set_index('정류장명', inplace=True)\n",
    "    \n",
    "    if title == '출근 시간대 Top 10 정류장 승차인원':\n",
    "        columns_to_plot = ['6시 승차인원', '7시 승차인원', '8시 승차인원', '9시 승차인원']\n",
    "    elif title == '퇴근 시간대 Top 10 정류장 승차인원':\n",
    "        columns_to_plot = ['17시 승차인원', '18시 승차인원', '19시 승차인원', '20시 승차인원', '21시 승차인원', '22시 승차인원']\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        return\n",
    "    \n",
    "    if columns_to_plot:\n",
    "        ax = df[columns_to_plot].T.plot(kind='bar', stacked=True, figsize=(15, 10), colormap='coolwarm')\n",
    "        plt.title(title)\n",
    "        plt.ylabel('승차인원')\n",
    "        plt.xlabel('시간대')\n",
    "        plt.legend(title='정류장명')\n",
    "        \n",
    "        # 각 막대 위에 텍스트 추가\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, label_type='center')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "plot_top_10(top_10_morning, '출근 시간대 Top 10 정류장 승차인원')\n",
    "plot_top_10(top_10_evening, '퇴근 시간대 Top 10 정류장 승차인원')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간과 퇴근 시간 동안의 승차 인원을 계산\n",
    "getOn_df['출근 시간 총 승차인원'] = getOn_df[['6시 승차인원', '7시 승차인원', '8시 승차인원', '9시 승차인원']].sum(axis=1)\n",
    "getOn_df['퇴근 시간 총 승차인원'] = getOn_df[['17시 승차인원', '18시 승차인원', '19시 승차인원', '20시 승차인원', '21시 승차인원', '22시 승차인원']].sum(axis=1)\n",
    "\n",
    "# 출근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_morning = getOn_df.nlargest(10, '출근 시간 총 승차인원')\n",
    "\n",
    "# 퇴근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_evening = getOn_df.nlargest(10, '퇴근 시간 총 승차인원')\n",
    "\n",
    "# Top 10 정류장의 시간대별 승차 인원수를 표로 표시\n",
    "def display_top_10_table(df, title):\n",
    "    if '출근 시간' in title:\n",
    "        columns_to_show = ['노선명', '정류장명', 'ARS_ID', '6시 승차인원', '7시 승차인원', '8시 승차인원', '9시 승차인원', '출근 시간 총 승차인원']\n",
    "    elif '퇴근 시간' in title:\n",
    "        columns_to_show = ['노선명', '정류장명', 'ARS_ID', '17시 승차인원', '18시 승차인원', '19시 승차인원', '20시 승차인원', '21시 승차인원', '22시 승차인원', '퇴근 시간 총 승차인원']\n",
    "    else:\n",
    "        columns_to_show = []\n",
    "    \n",
    "    if columns_to_show:\n",
    "        display_df = df[columns_to_show].copy()\n",
    "        display_df.set_index('정류장명', inplace=True)\n",
    "        display_df.style.set_caption(title).format(na_rep='-')\n",
    "\n",
    "        return display_df\n",
    "\n",
    "# 출근 시간대 Top 10 정류장 표\n",
    "morning_table = display_top_10_table(top_10_morning, '출근 시간대 Top 10 정류장 승차인원')\n",
    "\n",
    "# 퇴근 시간대 Top 10 정류장 표\n",
    "evening_table = display_top_10_table(top_10_evening, '퇴근 시간대 Top 10 정류장 승차인원')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하차 출근, 퇴근 시간 혼잡도(표, 막대 그래프)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간과 퇴근 시간 동안의 하차 인원을 계산\n",
    "getOff_df['출근 시간 총 하차인원'] = getOff_df[['6시 하차인원', '7시 하차인원', '8시 하차인원', '9시 하차인원']].sum(axis=1)\n",
    "getOff_df['퇴근 시간 총 하차인원'] = getOff_df[['17시 하차인원', '18시 하차인원', '19시 하차인원', '20시 하차인원', '21시 하차인원', '22시 하차인원']].sum(axis=1)\n",
    "\n",
    "# 출근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_morning_off = getOff_df.nlargest(10, '출근 시간 총 하차인원')\n",
    "\n",
    "# 퇴근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_evening_off = getOff_df.nlargest(10, '퇴근 시간 총 하차인원')\n",
    "\n",
    "# 정류장명과 노선명을 합치는 함수\n",
    "def combine_station_route(df):\n",
    "    df['정류장명'] = df['정류장명'] + ' (' + df['노선명'] + ')'\n",
    "    return df\n",
    "\n",
    "# 정류장명과 노선명을 합침\n",
    "top_10_morning_off = combine_station_route(top_10_morning_off)\n",
    "top_10_evening_off = combine_station_route(top_10_evening_off)\n",
    "\n",
    "# 색상 설정을 위한 함수\n",
    "def get_colors(values):\n",
    "    norm = mcolors.Normalize(vmin=values.min(), vmax=values.max())\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", [\"gray\", \"blue\"])\n",
    "    return [cmap(norm(val)) for val in values]\n",
    "\n",
    "# Top 10 정류장의 시간대별 하차 인원수 시각화\n",
    "def plot_top_10(df, title):\n",
    "    df.set_index('정류장명', inplace=True)\n",
    "    \n",
    "    if title == '출근 시간대 Top 10 정류장 하차인원':\n",
    "        columns_to_plot = ['6시 하차인원', '7시 하차인원', '8시 하차인원', '9시 하차인원']\n",
    "    elif title == '퇴근 시간대 Top 10 정류장 하차인원':\n",
    "        columns_to_plot = ['17시 하차인원', '18시 하차인원', '19시 하차인원', '20시 하차인원', '21시 하차인원', '22시 하차인원']\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        return\n",
    "    \n",
    "    if columns_to_plot:\n",
    "        ax = df[columns_to_plot].T.plot(kind='bar', stacked=True, figsize=(15, 10), colormap='coolwarm')\n",
    "        plt.title(title)\n",
    "        plt.ylabel('하차인원')\n",
    "        plt.xlabel('시간대')\n",
    "        plt.legend(title='정류장명')\n",
    "        \n",
    "        # 각 막대 위에 텍스트 추가\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, label_type='center')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "plot_top_10(top_10_morning_off, '출근 시간대 Top 10 정류장 하차인원')\n",
    "plot_top_10(top_10_evening_off, '퇴근 시간대 Top 10 정류장 하차인원')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간과 퇴근 시간 동안의 하차 인원을 계산\n",
    "getOff_df['출근 시간 총 하차인원'] = getOff_df[['6시 하차인원', '7시 하차인원', '8시 하차인원', '9시 하차인원']].sum(axis=1)\n",
    "getOff_df['퇴근 시간 총 하차인원'] = getOff_df[['17시 하차인원', '18시 하차인원', '19시 하차인원', '20시 하차인원', '21시 하차인원', '22시 하차인원']].sum(axis=1)\n",
    "\n",
    "# 출근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_morning_off = getOff_df.nlargest(10, '출근 시간 총 하차인원')\n",
    "\n",
    "# 퇴근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_evening_off = getOff_df.nlargest(10, '퇴근 시간 총 하차인원')\n",
    "\n",
    "# Top 10 정류장의 시간대별 하차 인원수를 표로 표시\n",
    "def display_top_10_off_table(df, title):\n",
    "    if '출근 시간' in title:\n",
    "        columns_to_show = ['노선명', '정류장명', 'ARS_ID', '6시 하차인원', '7시 하차인원', '8시 하차인원', '9시 하차인원', '출근 시간 총 하차인원']\n",
    "    elif '퇴근 시간' in title:\n",
    "        columns_to_show = ['노선명', '정류장명', 'ARS_ID', '17시 하차인원', '18시 하차인원', '19시 하차인원', '20시 하차인원', '21시 하차인원', '22시 하차인원', '퇴근 시간 총 하차인원']\n",
    "    else:\n",
    "        columns_to_show = []\n",
    "    \n",
    "    if columns_to_show:\n",
    "        display_df = df[columns_to_show].copy()\n",
    "        display_df.set_index('정류장명', inplace=True)\n",
    "        display_df.style.set_caption(title).format(na_rep='-')\n",
    "\n",
    "        return display_df\n",
    "\n",
    "# 출근 시간대 Top 10 정류장 표 (하차 인원)\n",
    "morning_table_off = display_top_10_off_table(top_10_morning_off, '출근 시간대 Top 10 정류장 하차인원')\n",
    "\n",
    "# 퇴근 시간대 Top 10 정류장 표 (하차 인원)\n",
    "evening_table_off = display_top_10_off_table(top_10_evening_off, '퇴근 시간대 Top 10 정류장 하차인원')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_table_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_table_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환승 출근, 퇴근 시간 혼잡도(표, 막대 그래프)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간과 퇴근 시간 동안의 환승 인원을 계산\n",
    "transfer_df['출근 시간 총 환승인원'] = transfer_df[['6시 환승인원', '7시 환승인원', '8시 환승인원', '9시 환승인원']].sum(axis=1)\n",
    "transfer_df['퇴근 시간 총 환승인원'] = transfer_df[['17시 환승인원', '18시 환승인원', '19시 환승인원', '20시 환승인원', '21시 환승인원', '22시 환승인원']].sum(axis=1)\n",
    "\n",
    "# 출근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_morning_transfer = transfer_df.nlargest(10, '출근 시간 총 환승인원')\n",
    "\n",
    "# 퇴근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_evening_transfer = transfer_df.nlargest(10, '퇴근 시간 총 환승인원')\n",
    "\n",
    "# 정류장명과 노선명을 합치는 함수\n",
    "def combine_station_route(df):\n",
    "    df['정류장명'] = df['정류장명'] + ' (' + df['노선명'] + ')'\n",
    "    return df\n",
    "\n",
    "# 정류장명과 노선명을 합침\n",
    "top_10_morning_transfer = combine_station_route(top_10_morning_transfer)\n",
    "top_10_evening_transfer = combine_station_route(top_10_evening_transfer)\n",
    "\n",
    "# 색상 설정을 위한 함수\n",
    "def get_colors(values):\n",
    "    norm = mcolors.Normalize(vmin=values.min(), vmax=values.max())\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_cmap\", [\"gray\", \"blue\"])\n",
    "    return [cmap(norm(val)) for val in values]\n",
    "\n",
    "# Top 10 정류장의 시간대별 환승 인원수 시각화\n",
    "def plot_top_10(df, title):\n",
    "    df.set_index('정류장명', inplace=True)\n",
    "    \n",
    "    if title == '출근 시간대 Top 10 정류장 환승인원':\n",
    "        columns_to_plot = ['6시 환승인원', '7시 환승인원', '8시 환승인원', '9시 환승인원']\n",
    "    elif title == '퇴근 시간대 Top 10 정류장 환승인원':\n",
    "        columns_to_plot = ['17시 환승인원', '18시 환승인원', '19시 환승인원', '20시 환승인원', '21시 환승인원', '22시 환승인원']\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        return\n",
    "    \n",
    "    if columns_to_plot:\n",
    "        ax = df[columns_to_plot].T.plot(kind='bar', stacked=True, figsize=(15, 10), colormap='coolwarm')\n",
    "        plt.title(title)\n",
    "        plt.ylabel('환승인원')\n",
    "        plt.xlabel('시간대')\n",
    "        plt.legend(title='정류장명')\n",
    "        \n",
    "        # 각 막대 위에 텍스트 추가\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, label_type='center')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "plot_top_10(top_10_morning_transfer, '출근 시간대 Top 10 정류장 환승인원')\n",
    "plot_top_10(top_10_evening_transfer, '퇴근 시간대 Top 10 정류장 환승인원')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간과 퇴근 시간 동안의 환승 인원을 계산\n",
    "transfer_df['출근 시간 총 환승인원'] = transfer_df[['6시 환승인원', '7시 환승인원', '8시 환승인원', '9시 환승인원']].sum(axis=1)\n",
    "transfer_df['퇴근 시간 총 환승인원'] = transfer_df[['17시 환승인원', '18시 환승인원', '19시 환승인원', '20시 환승인원', '21시 환승인원', '22시 환승인원']].sum(axis=1)\n",
    "\n",
    "# 출근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_morning_transfer = transfer_df.nlargest(10, '출근 시간 총 환승인원')\n",
    "\n",
    "# 퇴근 시간 기준으로 Top 10 정류장 선정\n",
    "top_10_evening_transfer = transfer_df.nlargest(10, '퇴근 시간 총 환승인원')\n",
    "\n",
    "# Top 10 정류장의 시간대별 환승 인원수를 표로 표시\n",
    "def display_top_10_transfer_table(df, title):\n",
    "    if '출근 시간' in title:\n",
    "        columns_to_show = ['노선명', '정류장명', 'ARS_ID', '6시 환승인원', '7시 환승인원', '8시 환승인원', '9시 환승인원', '출근 시간 총 환승인원']\n",
    "    elif '퇴근 시간' in title:\n",
    "        columns_to_show = ['노선명', '정류장명', 'ARS_ID', '17시 환승인원', '18시 환승인원', '19시 환승인원', '20시 환승인원', '21시 환승인원', '22시 환승인원', '퇴근 시간 총 환승인원']\n",
    "    else:\n",
    "        columns_to_show = []\n",
    "    \n",
    "    if columns_to_show:\n",
    "        display_df = df[columns_to_show].copy()\n",
    "        display_df.set_index('정류장명', inplace=True)\n",
    "        display_df.style.set_caption(title).format(na_rep='-')\n",
    "\n",
    "        return display_df\n",
    "\n",
    "# 출근 시간대 Top 10 정류장 표 (환승 인원)\n",
    "morning_table_transfer = display_top_10_transfer_table(top_10_morning_transfer, '출근 시간대 Top 10 정류장 환승인원')\n",
    "\n",
    "# 퇴근 시간대 Top 10 정류장 표 (환승 인원)\n",
    "evening_table_transfer = display_top_10_transfer_table(top_10_evening_transfer, '퇴근 시간대 Top 10 정류장 환승인원')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_table_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evening_table_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import MarkerCluster\n",
    "import folium\n",
    "\n",
    "# 중심점을 설정 (정류장명이 '구시청사거리'인 정류장의 위도, 경도)\n",
    "center_lat = getOn_df[getOn_df['정류장명'] == '구시청사거리']['위도'].values[0]\n",
    "center_lon = getOn_df[getOn_df['정류장명'] == '구시청사거리']['경도'].values[0]\n",
    "\n",
    "center = [center_lat, center_lon]\n",
    "\n",
    "# 지도 생성\n",
    "m = folium.Map(location=center, zoom_start=11)\n",
    "\n",
    "# 색상 설정 함수\n",
    "def get_color(type):\n",
    "    if type == '승차':\n",
    "        return 'blue'\n",
    "    elif type == '하차':\n",
    "        return 'red'\n",
    "    elif type == '환승':\n",
    "        return 'purple'\n",
    "\n",
    "# 출근 시간대 기준으로 Top 10 정류장 선정\n",
    "top_10_morning_on = getOn_df.nlargest(10, '출근 시간 총 승차인원')\n",
    "top_10_morning_off = getOff_df.nlargest(10, '출근 시간 총 하차인원')\n",
    "top_10_morning_transfer = transfer_df.nlargest(10, '출근 시간 총 환승인원')\n",
    "\n",
    "# 데이터 준비 및 마커 추가\n",
    "# 승차 데이터\n",
    "for index, row in top_10_morning_on.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['위도'], row['경도']),\n",
    "        icon=folium.Icon(color='blue', icon='info-sign'),\n",
    "        popup=(\n",
    "            f\"<strong>정류장명:</strong> {row['정류장명']}<br>\"\n",
    "            f\"<strong>출근 시간 총 승차인원:</strong> {row['출근 시간 총 승차인원']}명<br>\"\n",
    "            f\"<strong>유형:</strong> 승차<br>\"\n",
    "        ),\n",
    "        tooltip='승차'\n",
    "    ).add_to(m)\n",
    "\n",
    "# 하차 데이터\n",
    "for index, row in top_10_morning_off.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['위도'], row['경도']),\n",
    "        icon=folium.Icon(color='red', icon='info-sign'),\n",
    "        popup=(\n",
    "            f\"<strong>정류장명:</strong> {row['정류장명']}<br>\"\n",
    "            f\"<strong>출근 시간 총 하차인원:</strong> {row['출근 시간 총 하차인원']}명<br>\"\n",
    "            f\"<strong>유형:</strong> 하차<br>\"\n",
    "        ),\n",
    "        tooltip='하차'\n",
    "    ).add_to(m)\n",
    "\n",
    "# 환승 데이터\n",
    "for index, row in top_10_morning_transfer.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['위도'], row['경도']),\n",
    "        icon=folium.Icon(color='purple', icon='info-sign'),\n",
    "        popup=(\n",
    "            f\"<strong>정류장명:</strong> {row['정류장명']}<br>\"\n",
    "            f\"<strong>출근 시간 총 환승인원:</strong> {row['출근 시간 총 환승인원']}명<br>\"\n",
    "            f\"<strong>유형:</strong> 환승<br>\"\n",
    "        ),\n",
    "        tooltip='환승'\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "# 지도 저장\n",
    "m.save('2024 출근 시간대 승차 하차 환승 인원 포화상태.html')\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import MarkerCluster\n",
    "import folium\n",
    "\n",
    "# 중심점을 설정 (정류장명이 '구시청사거리'인 정류장의 위도, 경도)\n",
    "center_lat = getOn_df[getOn_df['정류장명'] == '구시청사거리']['위도'].values[0]\n",
    "center_lon = getOn_df[getOn_df['정류장명'] == '구시청사거리']['경도'].values[0]\n",
    "\n",
    "center = [center_lat, center_lon]\n",
    "\n",
    "# 지도 생성\n",
    "m = folium.Map(location=center, zoom_start=11)\n",
    "\n",
    "# 색상 설정 함수\n",
    "def get_color(type):\n",
    "    if type == '승차':\n",
    "        return 'blue'\n",
    "    elif type == '하차':\n",
    "        return 'red'\n",
    "    elif type == '환승':\n",
    "        return 'purple'\n",
    "\n",
    "# 퇴근 시간대 기준으로 Top 10 정류장 선정\n",
    "top_10_evening_on = getOn_df.nlargest(10, '퇴근 시간 총 승차인원')\n",
    "top_10_evening_off = getOff_df.nlargest(10, '퇴근 시간 총 하차인원')\n",
    "top_10_evening_transfer = transfer_df.nlargest(10, '퇴근 시간 총 환승인원')\n",
    "\n",
    "# 데이터 준비 및 마커 추가\n",
    "# 승차 데이터\n",
    "for index, row in top_10_evening_on.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['위도'], row['경도']),\n",
    "        icon=folium.Icon(color='blue', icon='info-sign'),\n",
    "        popup=(\n",
    "            f\"<strong>정류장명:</strong> {row['정류장명']}<br>\"\n",
    "            f\"<strong>퇴근 시간 총 승차인원:</strong> {row['퇴근 시간 총 승차인원']}명<br>\"\n",
    "            f\"<strong>유형:</strong> 승차<br>\"\n",
    "        ),\n",
    "        tooltip='승차'\n",
    "    ).add_to(m)\n",
    "\n",
    "# 하차 데이터\n",
    "for index, row in top_10_evening_off.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['위도'], row['경도']),\n",
    "        icon=folium.Icon(color='red', icon='info-sign'),\n",
    "        popup=(\n",
    "            f\"<strong>정류장명:</strong> {row['정류장명']}<br>\"\n",
    "            f\"<strong>퇴근 시간 총 하차인원:</strong> {row['퇴근 시간 총 하차인원']}명<br>\"\n",
    "            f\"<strong>유형:</strong> 하차<br>\"\n",
    "        ),\n",
    "        tooltip='하차'\n",
    "    ).add_to(m)\n",
    "\n",
    "# 환승 데이터\n",
    "for index, row in top_10_evening_transfer.iterrows():\n",
    "    folium.Marker(\n",
    "        location=(row['위도'], row['경도']),\n",
    "        icon=folium.Icon(color='purple', icon='info-sign'),\n",
    "        popup=(\n",
    "            f\"<strong>정류장명:</strong> {row['정류장명']}<br>\"\n",
    "            f\"<strong>퇴근 시간 총 환승인원:</strong> {row['퇴근 시간 총 환승인원']}명<br>\"\n",
    "            f\"<strong>유형:</strong> 환승<br>\"\n",
    "        ),\n",
    "        tooltip='환승'\n",
    "    ).add_to(m)\n",
    "\n",
    "# 지도 저장\n",
    "m.save('2024 퇴근 시간대 승차 하차 환승 인원 포화상태.html')\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출근 시간 승차, 하차, 환승 top10 겹치는 정거장 + 노선명 찾기 (3개다 겹치는 경우 X, 2개씩 겹치는 경우 찾기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출근 시간 동안의 승차, 하차, 환승 인원을 계산\n",
    "getOn_df['출근 시간 총 승차인원'] = transfer_df[['6시 환승인원', '7시 환승인원', '8시 환승인원', '9시 환승인원']].sum(axis=1)\n",
    "getOff_df['출근 시간 총 하차인원'] = transfer_df[['6시 환승인원', '7시 환승인원', '8시 환승인원', '9시 환승인원']].sum(axis=1)\n",
    "transfer_df['출근 시간 총 환승인원'] = transfer_df[['6시 환승인원', '7시 환승인원', '8시 환승인원', '9시 환승인원']].sum(axis=1)\n",
    "\n",
    "\n",
    "# 출근 시간대의 TOP 10 정류장 선정\n",
    "top_10_morning_on = getOn_df.nlargest(10, '출근 시간 총 승차인원')\n",
    "top_10_morning_off = getOff_df.nlargest(10, '출근 시간 총 하차인원')\n",
    "top_10_morning_transfer = transfer_df.nlargest(10, '출근 시간 총 환승인원')\n",
    "\n",
    "# 세 개의 조건에 따라 겹치는 정류장 찾기\n",
    "common_stations_all = top_10_morning_on.merge(\n",
    "    top_10_morning_off[['정류장명', '노선명', 'ARS_ID', '출근 시간 총 하차인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ").merge(\n",
    "    top_10_morning_transfer[['정류장명', '노선명', 'ARS_ID', '출근 시간 총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "# 두 개의 조건에 따라 겹치는 정류장 찾기\n",
    "common_stations_on_off = top_10_morning_on.merge(\n",
    "    top_10_morning_off[['정류장명', '노선명', 'ARS_ID', '출근 시간 총 하차인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "common_stations_on_transfer = top_10_morning_on.merge(\n",
    "    top_10_morning_transfer[['정류장명', '노선명', 'ARS_ID', '출근 시간 총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "common_stations_off_transfer = top_10_morning_off.merge(\n",
    "    top_10_morning_transfer[['정류장명', '노선명', 'ARS_ID', '출근 시간 총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "# 필요한 열만 선택하여 출력\n",
    "common_stations_all = common_stations_all[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_on_off = common_stations_on_off[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_on_transfer = common_stations_on_transfer[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_off_transfer = common_stations_off_transfer[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_on_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_on_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_off_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퇴근 시간 승차, 하차, 환승 top10 겹치는 정거장 + 노선명 찾기 (3개다 겹치는 경우 X, 2개씩 겹치는 경우 찾기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퇴근 시간대의 총 승차, 하차, 환승 인원 계산\n",
    "getOn_df['퇴근 시간 총 승차인원'] = getOn_df[['17시 승차인원', '18시 승차인원', '19시 승차인원', '20시 승차인원', '21시 승차인원', '22시 승차인원']].sum(axis=1)\n",
    "getOff_df['퇴근 시간 총 하차인원'] = getOff_df[['17시 하차인원', '18시 하차인원', '19시 하차인원', '20시 하차인원', '21시 하차인원', '22시 하차인원']].sum(axis=1)\n",
    "transfer_df['퇴근 시간 총 환승인원'] = transfer_df[['17시 환승인원', '18시 환승인원', '19시 환승인원', '20시 환승인원', '21시 환승인원', '22시 환승인원']].sum(axis=1)\n",
    "\n",
    "# 퇴근 시간대의 TOP 10 정류장 선정\n",
    "top_10_evening_on = getOn_df.nlargest(10, '퇴근 시간 총 승차인원')\n",
    "top_10_evening_off = getOff_df.nlargest(10, '퇴근 시간 총 하차인원')\n",
    "top_10_evening_transfer = transfer_df.nlargest(10, '퇴근 시간 총 환승인원')\n",
    "\n",
    "# 세 개의 조건에 따라 겹치는 정류장 찾기\n",
    "common_stations_all = top_10_evening_on.merge(\n",
    "    top_10_evening_off[['정류장명', '노선명', 'ARS_ID', '퇴근 시간 총 하차인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ").merge(\n",
    "    top_10_evening_transfer[['정류장명', '노선명', 'ARS_ID', '퇴근 시간 총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "# 두 개의 조건에 따라 겹치는 정류장 찾기\n",
    "common_stations_on_off = top_10_evening_on.merge(\n",
    "    top_10_evening_off[['정류장명', '노선명', 'ARS_ID', '퇴근 시간 총 하차인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "common_stations_on_transfer = top_10_evening_on.merge(\n",
    "    top_10_evening_transfer[['정류장명', '노선명', 'ARS_ID', '퇴근 시간 총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "common_stations_off_transfer = top_10_evening_off.merge(\n",
    "    top_10_evening_transfer[['정류장명', '노선명', 'ARS_ID', '퇴근 시간 총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "# 필요한 열만 선택하여 출력\n",
    "common_stations_all = common_stations_all[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_on_off = common_stations_on_off[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_on_transfer = common_stations_on_transfer[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_off_transfer = common_stations_off_transfer[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_on_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_on_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_off_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 정류장에 대한 총 승차, 하차, 환승 인원 수 top10(막대 그래프, 표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "# 한글 폰트 설정\n",
    "font_path = 'C:/Windows/Fonts/malgun.ttf'  # 윈도우 시스템에서 '맑은 고딕' 폰트 경로\n",
    "font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "plt.rc('font', family=font_name)\n",
    "\n",
    "# 모든 시간대의 총 승차, 하차, 환승 인원 계산\n",
    "getOn_df['총 승차인원'] = getOn_df.loc[:, '5시 승차인원':'23시 승차인원'].sum(axis=1)\n",
    "getOff_df['총 하차인원'] = getOff_df.loc[:, '5시 하차인원':'23시 하차인원'].sum(axis=1)\n",
    "transfer_df['총 환승인원'] = transfer_df.loc[:, '5시 환승인원':'23시 환승인원'].sum(axis=1)\n",
    "\n",
    "# 모든 시간대 기준으로 Top 10 정류장 선정\n",
    "top_10_all_time_on = getOn_df.nlargest(10, '총 승차인원')\n",
    "top_10_all_time_off = getOff_df.nlargest(10, '총 하차인원')\n",
    "top_10_all_time_transfer = transfer_df.nlargest(10, '총 환승인원')\n",
    "\n",
    "# Top 10 정류장의 총 승차, 하차, 환승 인원수를 막대 그래프로 시각화\n",
    "def plot_top_10_all_time(df, column, title, ylabel):\n",
    "    df.set_index('정류장명', inplace=True)\n",
    "    ax = df[column].plot(kind='bar', stacked=True, figsize=(15, 10), colormap='coolwarm')\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('정류장명')\n",
    "    plt.legend(title='정류장명')\n",
    "    \n",
    "    # 각 막대 위에 텍스트 추가\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, label_type='center')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 승차 인원 막대 그래프\n",
    "plot_top_10_all_time(top_10_all_time_on, '총 승차인원', '모든 시간대 Top 10 정류장 승차인원', '총 승차인원')\n",
    "\n",
    "# 하차 인원 막대 그래프\n",
    "plot_top_10_all_time(top_10_all_time_off, '총 하차인원', '모든 시간대 Top 10 정류장 하차인원', '총 하차인원')\n",
    "\n",
    "# 환승 인원 막대 그래프\n",
    "plot_top_10_all_time(top_10_all_time_transfer, '총 환승인원', '모든 시간대 Top 10 정류장 환승인원', '총 환승인원')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 모든 시간대의 총 승차, 하차, 환승 인원 계산\n",
    "getOn_df['총 승차인원'] = getOn_df.loc[:, '5시 승차인원':'23시 승차인원'].sum(axis=1)\n",
    "getOff_df['총 하차인원'] = getOff_df.loc[:, '5시 하차인원':'23시 하차인원'].sum(axis=1)\n",
    "transfer_df['총 환승인원'] = transfer_df.loc[:, '5시 환승인원':'23시 환승인원'].sum(axis=1)\n",
    "\n",
    "# 모든 시간대 기준으로 Top 10 정류장 선정\n",
    "top_10_all_time_on = getOn_df.nlargest(10, '총 승차인원')\n",
    "top_10_all_time_off = getOff_df.nlargest(10, '총 하차인원')\n",
    "top_10_all_time_transfer = transfer_df.nlargest(10, '총 환승인원')\n",
    "\n",
    "# Top 10 정류장의 총 승차, 하차, 환승 인원수를 표로 표시\n",
    "def display_top_10_all_time_table(df, column, title):\n",
    "    display_df = df[['정류장명', '노선명', 'ARS_ID', '위도', '경도', column]].copy()\n",
    "    display_df.set_index('정류장명', inplace=True)\n",
    "    display_df.style.set_caption(title).format(na_rep='-')\n",
    "\n",
    "    return display_df\n",
    "\n",
    "# 승차 인원 표\n",
    "top_10_all_time_on_table = display_top_10_all_time_table(top_10_all_time_on, '총 승차인원', '모든 시간대 Top 10 정류장 승차인원')\n",
    "\n",
    "# 하차 인원 표\n",
    "top_10_all_time_off_table = display_top_10_all_time_table(top_10_all_time_off, '총 하차인원', '모든 시간대 Top 10 정류장 하차인원')\n",
    "\n",
    "# 환승 인원 표\n",
    "top_10_all_time_transfer_table = display_top_10_all_time_table(top_10_all_time_transfer, '총 환승인원', '모든 시간대 Top 10 정류장 환승인원')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_all_time_on_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_all_time_off_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_all_time_transfer_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 정류장 승차, 하차, 환승 top10 겹치는게 있는지 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 시간대의 총 승차, 하차, 환승 인원 계산\n",
    "getOn_df['총 승차인원'] = getOn_df.loc[:, '5시 승차인원':'23시 승차인원'].sum(axis=1)\n",
    "getOff_df['총 하차인원'] = getOff_df.loc[:, '5시 하차인원':'23시 하차인원'].sum(axis=1)\n",
    "transfer_df['총 환승인원'] = transfer_df.loc[:, '5시 환승인원':'23시 환승인원'].sum(axis=1)\n",
    "\n",
    "# 모든 시간대 기준으로 Top 10 정류장 선정\n",
    "top_10_all_time_on = getOn_df.nlargest(10, '총 승차인원')\n",
    "top_10_all_time_off = getOff_df.nlargest(10, '총 하차인원')\n",
    "top_10_all_time_transfer = transfer_df.nlargest(10, '총 환승인원')\n",
    "\n",
    "# 세 조건에 따라 겹치는 정류장 찾기\n",
    "common_stations_all = top_10_all_time_on.merge(\n",
    "    top_10_all_time_off[['정류장명', '노선명', 'ARS_ID', '총 하차인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ").merge(\n",
    "    top_10_all_time_transfer[['정류장명', '노선명', 'ARS_ID', '총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "# 두 개의 조건에 따라 겹치는 정류장 찾기\n",
    "common_stations_on_off = top_10_all_time_on.merge(\n",
    "    top_10_all_time_off[['정류장명', '노선명', 'ARS_ID', '총 하차인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "common_stations_on_transfer = top_10_all_time_on.merge(\n",
    "    top_10_all_time_transfer[['정류장명', '노선명', 'ARS_ID', '총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "common_stations_off_transfer = top_10_all_time_off.merge(\n",
    "    top_10_all_time_transfer[['정류장명', '노선명', 'ARS_ID', '총 환승인원']],\n",
    "    on=['정류장명', '노선명', 'ARS_ID']\n",
    ")\n",
    "\n",
    "# 필요한 열만 선택하여 출력\n",
    "common_stations_all = common_stations_all[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_on_off = common_stations_on_off[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_on_transfer = common_stations_on_transfer[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n",
    "common_stations_off_transfer = common_stations_off_transfer[['일자', '정류장명', '노선명', 'ARS_ID', '위도', '경도']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_on_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_on_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stations_off_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
